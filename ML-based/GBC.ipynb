{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5879c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve, auc, mean_squared_error, \\\n",
    "    r2_score, mean_absolute_error,cohen_kappa_score,accuracy_score,f1_score,matthews_corrcoef,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "start = time.time()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def standardize(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "# the metrics for classification\n",
    "def statistical(y_true, y_pred, y_pro):\n",
    "    c_mat = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = list(c_mat.flatten())\n",
    "    se = tp / (tp + fn)\n",
    "    sp = tn / (tn + fp)\n",
    "    auc_prc = auc(precision_recall_curve(y_true, y_pro, pos_label=1)[1],\n",
    "                  precision_recall_curve(y_true, y_pro, pos_label=1)[0])\n",
    "    acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "#     acc_skl = accuracy_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pro)\n",
    "    recall = se\n",
    "#     recall_skl = recall_score(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "#     precision_skl = precision_score(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     f1_skl = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true,y_pred)\n",
    "    mcc = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) + 1e-8)\n",
    "#     mcc_skl = matthews_corrcoef(y_true,y_pred)\n",
    "    return tn,fp,fn,tp,se,sp,auc_prc,acc,auc_roc,recall,precision,f1,kappa,mcc\n",
    "\n",
    "def all_one_zeros(data):\n",
    "    if (len(np.unique(data)) == 2):\n",
    "        flag = False\n",
    "    else:\n",
    "        flag = True\n",
    "    return flag\n",
    "\n",
    "\n",
    "feature_selection = False\n",
    "tasks_dic = {'1-AR-Alva-6108-slim-Normalize-group.csv': ['activity']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1b755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'actual_estimator__n_estimators': IntUniformDistribution(high=300, low=10, step=1),\n",
    "#  'actual_estimator__learning_rate': LogUniformDistribution(high=0.5, low=1e-06),\n",
    "#  'actual_estimator__subsample': UniformDistribution(high=1.0, low=0.2),\n",
    "#  'actual_estimator__min_samples_split': IntUniformDistribution(high=10, low=2, step=1),\n",
    "#  'actual_estimator__min_samples_leaf': IntUniformDistribution(high=5, low=1, step=1),\n",
    "#  'actual_estimator__max_depth': IntUniformDistribution(high=11, low=1, step=1),\n",
    "#  'actual_estimator__min_impurity_decrease': LogUniformDistribution(high=0.5, low=1e-09),\n",
    "#  'actual_estimator__max_features': UniformDistribution(high=1.0, low=0.4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6daf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '1-AR-Alva-6108-slim-Normalize-group.csv'\n",
    "task_type = 'cla'  # 'reg' or 'cla'\n",
    "dataset_label = file_name.split('/')[-1].split('_')[0]\n",
    "tasks = tasks_dic[dataset_label]\n",
    "OPT_ITERS = 50\n",
    "repetitions = 10\n",
    "num_pools = 10\n",
    "unbalance = True\n",
    "patience = 100\n",
    "ecfp = True\n",
    "# space_ = {'min_samples_split': hp.choice('min_samples_split', range(200,2001,200)),\n",
    "#           'learning_rate': hp.uniform('learning_rate', 0.005, 0.3),\n",
    "#           'max_depth': hp.choice('max_depth', range(5,18,2)),\n",
    "#           'n_estimators': hp.choice('n_estimators', [40,60,80,100,200,300, 400, 500, 1000]),\n",
    "#           'min_samples_leaf': hp.choice('min_samples_leaf', range(30,71,10)),\n",
    "#           'max_features': hp.choice('max_features', range(7,20,2)),\n",
    "#           'subsample': hp.choice('subsample', [0.6,0.7,0.75,0.8,0.85,0.9]),\n",
    "#           }\n",
    "# min_samples_split_ls = range(200,2001,200)\n",
    "# max_depth_ls = range(5,18,2)\n",
    "# n_estimators_ls = [40,60,80,100,200,300, 400, 500, 1000]\n",
    "# min_samples_leaf_ls = range(30,71,10)\n",
    "# max_features_ls = range(7,20,2)\n",
    "# subsample_ls = [0.6,0.7,0.75,0.8,0.85,0.9]\n",
    "\n",
    "\n",
    "space_ = {'n_estimators': hp.choice('n_estimators', range(100,300,1)),\n",
    "          'learning_rate': hp.uniform('learning_rate', 0.01, 0.5),\n",
    "          'subsample': hp.uniform('subsample', 0.2, 1),\n",
    "          'min_samples_split': hp.choice('min_samples_split', range(2,10,1)),\n",
    "          'min_samples_leaf': hp.choice('min_samples_leaf', range(1,5,1)),\n",
    "          'max_depth': hp.choice('max_depth', range(1,11,1)),\n",
    "          'min_impurity_decrease': hp.loguniform('min_impurity_decrease', 1e-09, 0.5),\n",
    "          'max_features': hp.uniform('max_features', 0.4, 1)\n",
    "          }\n",
    "\n",
    "n_estimators_ls = range(100,300,1)\n",
    "min_samples_split_ls = range(2,10,1)\n",
    "min_samples_leaf_ls = range(1,5,1)\n",
    "max_depth_ls = range(1,11,1)\n",
    "\n",
    "dataset = pd.read_csv(file_name)\n",
    "pd_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5508043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the num of retained features for the 1-AR-Alva-6108-slim-Normalize-group.csv activity is: 1508\n",
      "the best hyper-parameters for 1-AR-Alva-6108-slim-Normalize-group.csv activity are:   {'learning_rate': 0.043542102383401976, 'max_depth': 4, 'max_features': 0.6794045063482032, 'min_impurity_decrease': 1.0008419523956456, 'min_samples_leaf': 0, 'min_samples_split': 6, 'n_estimators': 157, 'subsample': 0.9355366950532129}\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "train 0.985180944201913 0.964357034325852\n",
      "valid 0.9353237025147139 0.8452436034565978\n",
      "test 0.9284262485481998 0.8334215584561532\n"
     ]
    }
   ],
   "source": [
    "def hyper_runing(subtask):\n",
    "    cols = [subtask]\n",
    "    cols.extend(dataset.columns[(len(tasks) + 1):])\n",
    "    sub_dataset = dataset[cols]\n",
    "\n",
    "    # detect the na in the subtask (y cloumn)\n",
    "    rm_index = sub_dataset[subtask][sub_dataset[subtask].isnull()].index\n",
    "    sub_dataset.drop(index=rm_index, inplace=True)\n",
    "\n",
    "    # remove the features with na\n",
    "    sub_dataset = sub_dataset.dropna(axis=1)\n",
    "    # *******************\n",
    "    # demension reduction\n",
    "    # *******************\n",
    "    # Removing features with low variance\n",
    "    # threshold = 0.05\n",
    "    data_fea_var = sub_dataset.iloc[:, 2:].var()\n",
    "    del_fea1 = list(data_fea_var[data_fea_var <= 0.05].index)\n",
    "    sub_dataset.drop(columns=del_fea1, inplace=True)\n",
    "\n",
    "    # pair correlations\n",
    "    # threshold = 0.95\n",
    "    data_fea_corr = sub_dataset.iloc[:, 2:].corr()\n",
    "    del_fea2_col = []\n",
    "    del_fea2_ind = []\n",
    "    length = data_fea_corr.shape[1]\n",
    "    for i in range(length):\n",
    "        for j in range(i + 1, length):\n",
    "            if abs(data_fea_corr.iloc[i, j]) >= 0.95:\n",
    "                del_fea2_col.append(data_fea_corr.columns[i])\n",
    "                del_fea2_ind.append(data_fea_corr.index[j])\n",
    "    sub_dataset.drop(columns=del_fea2_ind, inplace=True)\n",
    "\n",
    "    # standardize the features\n",
    "    cols_ = list(sub_dataset.columns)[2:]\n",
    "    if not ecfp :\n",
    "        sub_dataset[cols_] = sub_dataset[cols_].apply(standardize, axis=0)\n",
    "\n",
    "    # get the attentivefp data splits\n",
    "    data_tr = sub_dataset[sub_dataset['group'] == 'train']\n",
    "    data_va = sub_dataset[sub_dataset['group'] == 'valid']\n",
    "    data_te = sub_dataset[sub_dataset['group'] == 'test']\n",
    "\n",
    "    # prepare data for training\n",
    "    # training set\n",
    "    data_tr_y = data_tr[subtask].values.reshape(-1, 1)\n",
    "    data_tr_x = np.array(data_tr.iloc[:, 2:].values)\n",
    "\n",
    "    # validation set\n",
    "    data_va_y = data_va[subtask].values.reshape(-1, 1)\n",
    "    data_va_x = np.array(data_va.iloc[:, 2:].values)\n",
    "\n",
    "    # test set\n",
    "    data_te_y = data_te[subtask].values.reshape(-1, 1)\n",
    "    data_te_x = np.array(data_te.iloc[:, 2:].values)\n",
    "\n",
    "    if feature_selection:\n",
    "        # univariate feature selection\n",
    "        trans1 = SelectPercentile(f_classif, percentile=80)\n",
    "        trans1.fit(data_tr_x, data_tr_y)\n",
    "        data_tr_x = trans1.transform(data_tr_x)\n",
    "        data_va_x = trans1.transform(data_va_x)\n",
    "        data_te_x = trans1.transform(data_te_x)\n",
    "\n",
    "        # select from model\n",
    "        clf = XGBClassifier(random_state=1)\n",
    "        clf = clf.fit(data_tr_x, data_tr_y)\n",
    "        trans2 = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "        data_tr_x = trans2.transform(data_tr_x)\n",
    "        data_va_x = trans2.transform(data_va_x)\n",
    "        data_te_x = trans2.transform(data_te_x)\n",
    "\n",
    "    num_fea = data_tr_x.shape[1]\n",
    "    print('the num of retained features for the ' + dataset_label + ' ' + subtask + ' is:', num_fea)\n",
    "\n",
    "    def hyper_opt(args):\n",
    "        model = GradientBoostingClassifier(**args, random_state=1) if task_type == 'cla' else GradientBoostingRegressor(**args,\n",
    "                                                                                                   random_state=1)\n",
    "\n",
    "        model.fit(data_tr_x, data_tr_y)\n",
    "        val_preds = model.predict_proba(data_va_x) if task_type == 'cla' else \\\n",
    "            model.predict(data_va_x)\n",
    "        loss = 1 - roc_auc_score(data_va_y, val_preds[:, 1]) if task_type == 'cla' else np.sqrt(\n",
    "            mean_squared_error(data_va_y, val_preds))\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    # start hyper-parameters optimization\n",
    "    trials = Trials()\n",
    "    best_results = fmin(hyper_opt, space_, algo=tpe.suggest, max_evals=OPT_ITERS, trials=trials, show_progressbar=False)\n",
    "    print('the best hyper-parameters for ' + dataset_label + ' ' + subtask + ' are:  ', best_results)\n",
    "\n",
    "    best_model = GradientBoostingClassifier(\n",
    "                                        n_estimators= n_estimators_ls[best_results['n_estimators']],\n",
    "                                        learning_rate=best_results['learning_rate'],\n",
    "                                        subsample=best_results['subsample'],\n",
    "                                        min_samples_split=min_samples_split_ls[best_results['min_samples_split']],\n",
    "                                        min_samples_leaf=min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                                        max_depth=max_depth_ls[best_results['max_depth']],\n",
    "                                        min_impurity_decrease=best_results['min_impurity_decrease'],\n",
    "                                        max_features=best_results['max_features'],\n",
    "                                        random_state=1, verbose=-1) \\\n",
    "        if task_type == 'cla' else GradientBoostingRegressor(\n",
    "                                        n_estimators= n_estimators_ls[best_results['n_estimators']],\n",
    "                                        learning_rate=best_results['learning_rate'],\n",
    "                                        subsample=best_results['subsample'],\n",
    "                                        min_samples_split=min_samples_split_ls[best_results['min_samples_split']],\n",
    "                                        min_samples_leaf=min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                                        max_depth=max_depth_ls[best_results['max_depth']],\n",
    "                                        min_impurity_decrease=best_results['min_impurity_decrease'],\n",
    "                                        max_features=best_results['max_features'],\n",
    "                                        random_state=1, verbose=-1)  \n",
    "    \n",
    "    best_model.fit(data_tr_x, data_tr_y)\n",
    "    \n",
    "    num_of_compounds = len(sub_dataset)\n",
    "\n",
    "    if task_type == 'cla':\n",
    "        # training set\n",
    "        tr_pred = best_model.predict_proba(data_tr_x)\n",
    "        tr_results = [dataset_label, subtask, 'tr', num_fea, num_of_compounds, data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0] / data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      best_results['learning_rate'],\n",
    "                      best_results['subsample'],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      best_results['max_features']\n",
    "                     ]\n",
    "        tr_results.extend(statistical(data_tr_y, np.argmax(tr_pred, axis=1), tr_pred[:, 1]))\n",
    "        # validation set\n",
    "        va_pred = best_model.predict_proba(data_va_x)\n",
    "                      \n",
    "        va_results = [dataset_label, subtask, 'va', num_fea, num_of_compounds, data_va_y[data_va_y == 1].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0] / data_va_y[data_va_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      best_results['learning_rate'],\n",
    "                      best_results['subsample'],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      best_results['max_features']\n",
    "                     ]\n",
    "        va_results.extend(statistical(data_va_y, np.argmax(va_pred, axis=1), va_pred[:, 1]))\n",
    "\n",
    "        # test set\n",
    "        te_pred = best_model.predict_proba(data_te_x)\n",
    "        te_results = [dataset_label, subtask, 'te', num_fea, num_of_compounds, data_te_y[data_te_y == 1].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0] / data_te_y[data_te_y == 1].shape[0],\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      best_results['learning_rate'],\n",
    "                      best_results['subsample'],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      best_results['max_features']\n",
    "                     ]\n",
    "        te_results.extend(statistical(data_te_y, np.argmax(te_pred, axis=1), te_pred[:, 1]))\n",
    "    else:\n",
    "        # training set\n",
    "        tr_pred = best_model.predict(data_tr_x)\n",
    "        tr_results = [dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      best_results['learning_rate'],\n",
    "                      best_results['subsample'],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      best_results['max_features'],\n",
    "                      np.sqrt(mean_squared_error(data_tr_y, tr_pred)), r2_score(data_tr_y, tr_pred),\n",
    "                      mean_absolute_error(data_tr_y, tr_pred)]\n",
    "\n",
    "        # validation set\n",
    "        va_pred = best_model.predict(data_va_x)\n",
    "        va_results = [dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      best_results['learning_rate'],\n",
    "                      best_results['subsample'],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      best_results['max_features'],\n",
    "                      np.sqrt(mean_squared_error(data_va_y, va_pred)), r2_score(data_va_y, va_pred),\n",
    "                      mean_absolute_error(data_va_y, va_pred)]\n",
    "\n",
    "        # test set\n",
    "        te_pred = best_model.predict(data_te_x)\n",
    "        te_results = [dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      n_estimators_ls[best_results['n_estimators']],\n",
    "                      best_results['learning_rate'],\n",
    "                      best_results['subsample'],\n",
    "                      min_samples_split_ls[best_results['min_samples_split']],\n",
    "                      min_samples_leaf_ls[best_results['min_samples_leaf']],\n",
    "                      max_depth_ls[best_results['max_depth']],\n",
    "                      best_results['min_impurity_decrease'],\n",
    "                      best_results['max_features'],\n",
    "                      np.sqrt(mean_squared_error(data_te_y, te_pred)), r2_score(data_te_y, te_pred),\n",
    "                      mean_absolute_error(data_te_y, te_pred)]\n",
    "    return tr_results, va_results, te_results\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(num_pools)\n",
    "res = pool.starmap(hyper_runing, zip(tasks))\n",
    "pool.close()\n",
    "pool.join()\n",
    "for item in res:\n",
    "    for i in range(3):\n",
    "        pd_res.append(item[i])\n",
    "if task_type == 'cla':       \n",
    "                                            \n",
    "    best_hyper = pd.DataFrame(pd_res, columns=['dataset', 'subtask', 'set',\n",
    "                                               'num_of_retained_feature',\n",
    "                                               'num_of_compounds', 'postives',\n",
    "                                               'negtives', 'negtives/postives',\n",
    "                                               'n_estimators', \n",
    "                                               'learning_rate','subsample','min_samples_split','min_samples_leaf',\n",
    "                                               'max_depth','min_impurity_decrease','max_features',\n",
    "                                               'tn', 'fp', 'fn', 'tp', 'se', 'sp',\n",
    "                                               'auc_prc', 'acc', 'auc_roc','recall','precision','f1','kappa','mcc'])\n",
    "else:\n",
    "    best_hyper = pd.DataFrame(pd_res, columns=['dataset', 'subtask', 'set',\n",
    "                                               'n_estimators', \n",
    "                                               'learning_rate','subsample','min_samples_split','min_samples_leaf',\n",
    "                                               'max_depth','min_impurity_decrease','max_features',\n",
    "                                               'rmse', 'r2', 'mae'])\n",
    "best_hyper.to_csv('./model/' + dataset_label + '_GBC_hyperopt_info.csv', index=0)\n",
    "\n",
    "if task_type == 'cla':\n",
    "    print('train', best_hyper[best_hyper['set'] == 'tr']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'tr']['auc_prc'].mean())\n",
    "    print('valid', best_hyper[best_hyper['set'] == 'va']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'va']['auc_prc'].mean())\n",
    "    print('test', best_hyper[best_hyper['set'] == 'te']['auc_roc'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'te']['auc_prc'].mean())\n",
    "else:\n",
    "    print('train', best_hyper[best_hyper['set'] == 'tr']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'tr']['r2'].mean(), best_hyper[best_hyper['set'] == 'tr']['mae'].mean())\n",
    "    print('valid', best_hyper[best_hyper['set'] == 'va']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'va']['r2'].mean(), best_hyper[best_hyper['set'] == 'va']['mae'].mean())\n",
    "    print('test', best_hyper[best_hyper['set'] == 'te']['rmse'].mean(),\n",
    "          best_hyper[best_hyper['set'] == 'te']['r2'].mean(), best_hyper[best_hyper['set'] == 'te']['mae'].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e5b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 repetitions based on thr best hypers\n",
    "dataset.drop(columns=['group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49892864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed used in repetition 3 is 3\n",
      "random seed used in repetition 4 is 4\n",
      "random seed used in repetition 1 is 1\n",
      "random seed used in repetition 6 is 6\n",
      "random seed used in repetition 7 is 7\n",
      "random seed used in repetition 5 is 5\n",
      "random seed used in repetition 9 is 9\n",
      "random seed used in repetition 2 is 2\n",
      "random seed used in repetition 10 is 10\n",
      "random seed used in repetition 8 is 8\n",
      "1-AR-Alva-6108-slim-Normalize-group.csv_GBC: the mean auc_roc for the training set is 0.984 with std 0.001\n",
      "1-AR-Alva-6108-slim-Normalize-group.csv_GBC: the mean auc_roc for the validation set is 0.932 with std 0.011\n",
      "1-AR-Alva-6108-slim-Normalize-group.csv_GBC: the mean auc_roc for the test set is 0.932 with std 0.008\n",
      "the total elapsed time is: 3319.5983517169952 S\n"
     ]
    }
   ],
   "source": [
    "pd_res = []\n",
    "def best_model_runing(split):\n",
    "    seed = split\n",
    "    if task_type == 'cla':\n",
    "        while True:\n",
    "            training_data, data_te = train_test_split(sub_dataset, test_size=0.1, random_state=seed)\n",
    "            # the training set was further splited into the training set and validation set\n",
    "            data_tr, data_va = train_test_split(training_data, test_size=0.1, random_state=seed)\n",
    "            if (all_one_zeros(data_tr[subtask]) or all_one_zeros(data_va[subtask]) or all_one_zeros(data_te[subtask])):\n",
    "                print(\n",
    "                    '\\ninvalid random seed {} due to one class presented in the {} splitted sets...'.format(seed,\n",
    "                                                                                                            subtask))\n",
    "                print('Changing to another random seed...\\n')\n",
    "                seed = np.random.randint(10, 999999)\n",
    "            else:\n",
    "                print('random seed used in repetition {} is {}'.format(split, seed))\n",
    "                break\n",
    "    else:\n",
    "        training_data, data_te = train_test_split(sub_dataset, test_size=0.1, random_state=seed)\n",
    "        # the training set was further splited into the training set and validation set\n",
    "        data_tr, data_va = train_test_split(training_data, test_size=0.1, random_state=seed)\n",
    "\n",
    "    # prepare data for training\n",
    "    # training set\n",
    "    data_tr_y = data_tr[subtask].values.reshape(-1, 1)\n",
    "    data_tr_x = np.array(data_tr.iloc[:, 1:].values)\n",
    "\n",
    "    # validation set\n",
    "    data_va_y = data_va[subtask].values.reshape(-1, 1)\n",
    "    data_va_x = np.array(data_va.iloc[:, 1:].values)\n",
    "\n",
    "    # test set\n",
    "    data_te_y = data_te[subtask].values.reshape(-1, 1)\n",
    "    data_te_x = np.array(data_te.iloc[:, 1:].values)\n",
    "\n",
    "    if feature_selection:\n",
    "        # univariate feature selection\n",
    "        trans1 = SelectPercentile(f_classif, percentile=80)\n",
    "        trans1.fit(data_tr_x, data_tr_y)\n",
    "        data_tr_x = trans1.transform(data_tr_x)\n",
    "        data_va_x = trans1.transform(data_va_x)\n",
    "        data_te_x = trans1.transform(data_te_x)\n",
    "\n",
    "        # select from model\n",
    "        clf = XGBClassifier(random_state=1)\n",
    "        clf = clf.fit(data_tr_x, data_tr_y)\n",
    "        trans2 = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "        data_tr_x = trans2.transform(data_tr_x)\n",
    "        data_va_x = trans2.transform(data_va_x)\n",
    "        data_te_x = trans2.transform(data_te_x)\n",
    "\n",
    "    num_fea = data_tr_x.shape[1]\n",
    "    pos_weight = (len(sub_dataset) - sum(sub_dataset[subtask])) / sum(sub_dataset[subtask])\n",
    "    model = GradientBoostingClassifier(\n",
    "                          n_estimators=best_hyper[best_hyper.subtask == subtask].iloc[0,]['n_estimators'],\n",
    "                          learning_rate=best_hyper[best_hyper.subtask == subtask].iloc[0,]['learning_rate'],\n",
    "                          subsample=best_hyper[best_hyper.subtask == subtask].iloc[0,]['subsample'],\n",
    "                          min_samples_split=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_split'],\n",
    "                          min_samples_leaf=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_leaf'],\n",
    "                          max_depth=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_depth'],\n",
    "                          min_impurity_decrease=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_impurity_decrease'],\n",
    "                          max_features=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_features'],\n",
    "                          random_state=1) \\\n",
    "        if task_type == 'cla' else GradientBoostingRegressor(\n",
    "                          n_estimators=best_hyper[best_hyper.subtask == subtask].iloc[0,]['n_estimators'],\n",
    "                          learning_rate=best_hyper[best_hyper.subtask == subtask].iloc[0,]['learning_rate'],\n",
    "                          subsample=best_hyper[best_hyper.subtask == subtask].iloc[0,]['subsample'],\n",
    "                          min_samples_split=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_split'],\n",
    "                          min_samples_leaf=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_samples_leaf'],\n",
    "                          max_depth=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_depth'],\n",
    "                          min_impurity_decrease=best_hyper[best_hyper.subtask == subtask].iloc[0,]['min_impurity_decrease'],\n",
    "                          max_features=best_hyper[best_hyper.subtask == subtask].iloc[0,]['max_features'],\n",
    "        random_state=1, seed=1)\n",
    "\n",
    "    model.fit(data_tr_x, data_tr_y)\n",
    "    num_of_compounds = sub_dataset.shape[0]\n",
    "    import pickle\n",
    "    pickle.dump(model, open(\"./model/gbc_\"+str(split)+\".pkl\", \"wb\"))\n",
    "    if task_type == 'cla':\n",
    "        # training set\n",
    "        tr_pred = model.predict_proba(data_tr_x)\n",
    "        tr_results = [split, dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      data_tr_y[data_tr_y == 1].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0],\n",
    "                      data_tr_y[data_tr_y == 0].shape[0] / data_tr_y[data_tr_y == 1].shape[0]]\n",
    "        tr_results.extend(statistical(data_tr_y, np.argmax(tr_pred, axis=1), tr_pred[:, 1]))\n",
    "\n",
    "        # validation set\n",
    "        va_pred = model.predict_proba(data_va_x)\n",
    "        va_results = [split, dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      data_va_y[data_va_y == 1].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0],\n",
    "                      data_va_y[data_va_y == 0].shape[0] / data_va_y[data_va_y == 1].shape[0]]\n",
    "        va_results.extend(statistical(data_va_y, np.argmax(va_pred, axis=1), va_pred[:, 1]))\n",
    "\n",
    "        # test set\n",
    "        te_pred = model.predict_proba(data_te_x)\n",
    "        te_results = [split, dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      data_te_y[data_te_y == 1].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0],\n",
    "                      data_te_y[data_te_y == 0].shape[0] / data_te_y[data_te_y == 1].shape[0]]\n",
    "        te_results.extend(statistical(data_te_y, np.argmax(te_pred, axis=1), te_pred[:, 1]))\n",
    "    else:\n",
    "        # training set\n",
    "        tr_pred = model.predict(data_tr_x)\n",
    "        tr_results = [split, dataset_label, subtask, 'tr', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_tr_y, tr_pred)), r2_score(data_tr_y, tr_pred),\n",
    "                      mean_absolute_error(data_tr_y, tr_pred)]\n",
    "\n",
    "        # validation set\n",
    "        va_pred = model.predict(data_va_x)\n",
    "        va_results = [split, dataset_label, subtask, 'va', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_va_y, va_pred)), r2_score(data_va_y, va_pred),\n",
    "                      mean_absolute_error(data_va_y, va_pred)]\n",
    "\n",
    "        # test set\n",
    "        te_pred = model.predict(data_te_x)\n",
    "        te_results = [split, dataset_label, subtask, 'te', num_fea, num_of_compounds,\n",
    "                      np.sqrt(mean_squared_error(data_te_y, te_pred)), r2_score(data_te_y, te_pred),\n",
    "                      mean_absolute_error(data_te_y, te_pred)]\n",
    "    return tr_results, va_results, te_results\n",
    "\n",
    "\n",
    "for subtask in tasks:\n",
    "    cols = [subtask]\n",
    "    cols.extend(dataset.columns[(len(tasks) + 1):])\n",
    "    sub_dataset = dataset[cols]\n",
    "\n",
    "    # detect the NA in the subtask (y cloumn)\n",
    "    rm_index = sub_dataset[subtask][sub_dataset[subtask].isnull()].index\n",
    "    sub_dataset.drop(index=rm_index, inplace=True)\n",
    "\n",
    "    # remove the features with na\n",
    "    sub_dataset = sub_dataset.dropna(axis=1)\n",
    "    # *******************\n",
    "    # demension reduction\n",
    "    # *******************\n",
    "    # Removing features with low variance\n",
    "    # threshold = 0.05\n",
    "    data_fea_var = sub_dataset.iloc[:, 1:].var()\n",
    "    del_fea1 = list(data_fea_var[data_fea_var <= 0.05].index)\n",
    "    sub_dataset.drop(columns=del_fea1, inplace=True)\n",
    "\n",
    "    # pair correlations\n",
    "    # threshold = 0.95\n",
    "    data_fea_corr = sub_dataset.iloc[:, 1:].corr()\n",
    "    del_fea2_col = []\n",
    "    del_fea2_ind = []\n",
    "    length = data_fea_corr.shape[1]\n",
    "    for i in range(length):\n",
    "        for j in range(i + 1, length):\n",
    "            if abs(data_fea_corr.iloc[i, j]) >= 0.95:\n",
    "                del_fea2_col.append(data_fea_corr.columns[i])\n",
    "                del_fea2_ind.append(data_fea_corr.index[j])\n",
    "    sub_dataset.drop(columns=del_fea2_ind, inplace=True)\n",
    "\n",
    "    # standardize the features\n",
    "    cols_ = list(sub_dataset.columns)[1:]\n",
    "    if not ecfp :\n",
    "        sub_dataset[cols_] = sub_dataset[cols_].apply(standardize, axis=0)\n",
    "\n",
    "    # for split in range(1, splits+1):\n",
    "    pool = multiprocessing.Pool(num_pools)\n",
    "    res = pool.starmap(best_model_runing, zip(range(1, repetitions + 1)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for item in res:\n",
    "        for i in range(3):\n",
    "            pd_res.append(item[i])\n",
    "if task_type == 'cla':\n",
    "    stat_res = pd.DataFrame(pd_res, columns=['split', 'dataset', 'subtask', 'set',\n",
    "                                             'num_of_retained_feature',\n",
    "                                             'num_of_compounds', 'postives',\n",
    "                                             'negtives', 'negtives/postives',\n",
    "                                             'tn', 'fp', 'fn', 'tp', 'se', 'sp',\n",
    "                                             'auc_prc', 'acc', 'auc_roc','recall','precision','f1','kappa','mcc'])\n",
    "else:\n",
    "    stat_res = pd.DataFrame(pd_res, columns=['split', 'dataset', 'subtask', 'set',\n",
    "                                             'num_of_retained_feature',\n",
    "                                             'num_of_compounds', 'rmse', 'r2', 'mae'])\n",
    "stat_res.to_csv('./model/' + dataset_label + '_GBC_statistical_results_split.csv', index=0)\n",
    "# single tasks\n",
    "if len(tasks) == 1:\n",
    "    args = {'data_label': dataset_label, 'metric': 'auc_roc' if task_type == 'cla' else 'rmse', 'model': 'GBC'}\n",
    "    print('{}_{}: the mean {} for the training set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(\n",
    "            stat_res[stat_res['set'] == 'tr'][args['metric']]), np.std(\n",
    "            stat_res[stat_res['set'] == 'tr'][args['metric']])))\n",
    "    print(\n",
    "        '{}_{}: the mean {} for the validation set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(\n",
    "                stat_res[stat_res['set'] == 'va'][args['metric']]), np.std(\n",
    "                stat_res[stat_res['set'] == 'va'][args['metric']])))\n",
    "    print('{}_{}: the mean {} for the test set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                 args['metric'], np.mean(\n",
    "            stat_res[stat_res['set'] == 'te'][args['metric']]), np.std(\n",
    "            stat_res[stat_res['set'] == 'te'][args['metric']])))\n",
    "# multi-tasks\n",
    "else:\n",
    "    args = {'data_label': dataset_label, 'metric': 'auc_roc' if dataset_label != 'muv' else 'auc_prc', 'model': 'GBC'}\n",
    "    tr_acc = np.zeros(repetitions)\n",
    "    va_acc = np.zeros(repetitions)\n",
    "    te_acc = np.zeros(repetitions)\n",
    "    for subtask in tasks:\n",
    "        tr = stat_res[stat_res['set'] == 'tr']\n",
    "        tr_acc = tr_acc + tr[tr['subtask'] == subtask][args['metric']].values\n",
    "\n",
    "        va = stat_res[stat_res['set'] == 'va']\n",
    "        va_acc = va_acc + va[va['subtask'] == subtask][args['metric']].values\n",
    "\n",
    "        te = stat_res[stat_res['set'] == 'te']\n",
    "        te_acc = te_acc + te[te['subtask'] == subtask][args['metric']].values\n",
    "    tr_acc = tr_acc / len(tasks)\n",
    "    va_acc = va_acc / len(tasks)\n",
    "    te_acc = te_acc / len(tasks)\n",
    "    print('{}_{}: the mean {} for the training set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(tr_acc),\n",
    "                                                                                     np.std(tr_acc)))\n",
    "    print(\n",
    "        '{}_{}: the mean {} for the validation set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                     args['metric'], np.mean(va_acc),\n",
    "                                                                                     np.std(va_acc)))\n",
    "    print('{}_{}: the mean {} for the test set is {:.3f} with std {:.3f}'.format(args['data_label'], args['model'],\n",
    "                                                                                 args['metric'], np.mean(te_acc),\n",
    "                                                                                 np.std(te_acc)))\n",
    "end = time.time()  # get the end time\n",
    "print('the total elapsed time is:', (end - start), 'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50bc4eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the elapsed time is: 0.9221106532547209 H\n"
     ]
    }
   ],
   "source": [
    "# acc auc_roc recall precision f1 kappa mcc\n",
    "acc_str = 'acc of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['acc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['acc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['acc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['acc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['acc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['acc']),\n",
    ")\n",
    "auc_str = 'auc_roc of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['auc_roc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['auc_roc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['auc_roc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['auc_roc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['auc_roc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['auc_roc']),\n",
    ")\n",
    "recall_str = 'recall of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['recall']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['recall']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['recall']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['recall']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['recall']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['recall']),\n",
    ")\n",
    "precision_str = 'precision of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['precision']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['precision']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['precision']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['precision']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['precision']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['precision']),\n",
    ")\n",
    "f1_str = 'f1 of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['f1']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['f1']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['f1']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['f1']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['f1']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['f1']),\n",
    ")\n",
    "kappa_str = 'kappa of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['kappa']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['kappa']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['kappa']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['kappa']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['kappa']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['kappa']),\n",
    ")\n",
    "mcc_str = 'mcc of training set is {:.3f}±{:.3f}, validation set is {:.3f}±{:.3f}, test set is {:.3f}±{:.3f}'.format(\n",
    "                np.mean(stat_res[stat_res['set'] == 'tr']['mcc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'tr']['mcc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'va']['mcc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'va']['mcc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['mcc']), \n",
    "                np.std(stat_res[stat_res['set'] == 'te']['mcc']),\n",
    ")\n",
    "print('the elapsed time is:', (end - start)/3600, 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb4f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of training set is 0.954±0.001, validation set is 0.909±0.011, test set is 0.908±0.009\n",
      "auc_roc of training set is 0.984±0.001, validation set is 0.932±0.011, test set is 0.932±0.008\n",
      "recall of training set is 0.770±0.010, validation set is 0.607±0.028, test set is 0.601±0.028\n",
      "precision of training set is 0.985±0.003, validation set is 0.891±0.028, test set is 0.891±0.038\n",
      "f1 of training set is 0.864±0.006, validation set is 0.721±0.021, test set is 0.717±0.021\n",
      "kappa of training set is 0.837±0.007, validation set is 0.669±0.025, test set is 0.664±0.025\n",
      "mcc of training set is 0.846±0.006, validation set is 0.687±0.023, test set is 0.683±0.024\n"
     ]
    }
   ],
   "source": [
    "print(acc_str)\n",
    "print(auc_str)\n",
    "print(recall_str)\n",
    "print(precision_str)\n",
    "print(f1_str)\n",
    "print(kappa_str)\n",
    "print(mcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4ebafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/output_gbc.txt', 'w') as f:\n",
    "    f.write(acc_str+'\\n')\n",
    "    f.write(auc_str+'\\n')\n",
    "    f.write(recall_str+'\\n')\n",
    "    f.write(precision_str+'\\n')\n",
    "    f.write(f1_str+'\\n')\n",
    "    f.write(kappa_str+'\\n')\n",
    "    f.write(mcc_str+'\\n')\n",
    "    f.write(str(cols_)+'\\n')\n",
    "cols_ = pd.DataFrame(cols_)\n",
    "cols_.to_csv('output/output_gbc_cols.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaad1fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model: GBC</th>\n",
       "      <th>Train</th>\n",
       "      <th>Tr_STD</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Va_STD</th>\n",
       "      <th>Test</th>\n",
       "      <th>Te_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.954093</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.009148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc_roc</td>\n",
       "      <td>0.984051</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.932055</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.931872</td>\n",
       "      <td>0.008180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.770138</td>\n",
       "      <td>0.010286</td>\n",
       "      <td>0.606812</td>\n",
       "      <td>0.028175</td>\n",
       "      <td>0.601311</td>\n",
       "      <td>0.028115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.890642</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.890852</td>\n",
       "      <td>0.037644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.864347</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.721240</td>\n",
       "      <td>0.021201</td>\n",
       "      <td>0.717079</td>\n",
       "      <td>0.020759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kappa</td>\n",
       "      <td>0.837216</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.669264</td>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.664490</td>\n",
       "      <td>0.025020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.846422</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.687283</td>\n",
       "      <td>0.023204</td>\n",
       "      <td>0.683433</td>\n",
       "      <td>0.023511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>auc_prc</td>\n",
       "      <td>0.960951</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.843106</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>0.841070</td>\n",
       "      <td>0.012003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model: GBC      Train    Tr_STD  Validation    Va_STD      Test    Te_STD\n",
       "0         acc  0.954093  0.001333    0.909091  0.010818  0.907692  0.009148\n",
       "1     auc_roc  0.984051  0.001391    0.932055  0.010545  0.931872  0.008180\n",
       "2      recall  0.770138  0.010286    0.606812  0.028175  0.601311  0.028115\n",
       "3   precision  0.984940  0.003336    0.890642  0.027841  0.890852  0.037644\n",
       "4          f1  0.864347  0.006185    0.721240  0.021201  0.717079  0.020759\n",
       "5       kappa  0.837216  0.006783    0.669264  0.025356  0.664490  0.025020\n",
       "6         mcc  0.846422  0.005930    0.687283  0.023204  0.683433  0.023511\n",
       "7     auc_prc  0.960951  0.002153    0.843106  0.019368  0.841070  0.012003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "dict1 = {\"Model: GBC \":['acc','auc_roc','recall','precision','f1','kappa','mcc','auc_prc'],\n",
    "         \"Train\":[np.mean(stat_res[stat_res['set'] == 'tr']['acc']),np.mean(stat_res[stat_res['set'] == 'tr']['auc_roc']),\n",
    "                  np.mean(stat_res[stat_res['set'] == 'tr']['recall']),np.mean(stat_res[stat_res['set'] == 'tr']['precision']),\n",
    "                  np.mean(stat_res[stat_res['set'] == 'tr']['f1']),np.mean(stat_res[stat_res['set'] == 'tr']['kappa']),\n",
    "                  np.mean(stat_res[stat_res['set'] == 'tr']['mcc']),np.mean(stat_res[stat_res['set'] == 'tr']['auc_prc']),                                     \n",
    "                 ],\n",
    "         \"Tr_STD\":[np.std(stat_res[stat_res['set'] == 'tr']['acc']),np.std(stat_res[stat_res['set'] == 'tr']['auc_roc']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'tr']['recall']),np.std(stat_res[stat_res['set'] == 'tr']['precision']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'tr']['f1']),np.std(stat_res[stat_res['set'] == 'tr']['kappa']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'tr']['mcc']),np.std(stat_res[stat_res['set'] == 'tr']['auc_prc']),],\n",
    "         \"Validation\":[np.mean(stat_res[stat_res['set'] == 'va']['acc']),np.mean(stat_res[stat_res['set'] == 'va']['auc_roc']),\n",
    "                      np.mean(stat_res[stat_res['set'] == 'va']['recall']),np.mean(stat_res[stat_res['set'] == 'va']['precision']),\n",
    "                      np.mean(stat_res[stat_res['set'] == 'va']['f1']),np.mean(stat_res[stat_res['set'] == 'va']['kappa']),\n",
    "                      np.mean(stat_res[stat_res['set'] == 'va']['mcc']),np.mean(stat_res[stat_res['set'] == 'va']['auc_prc'])],\n",
    "         \"Va_STD\":[np.std(stat_res[stat_res['set'] == 'va']['acc']),np.std(stat_res[stat_res['set'] == 'va']['auc_roc']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'va']['recall']),np.std(stat_res[stat_res['set'] == 'va']['precision']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'va']['f1']),np.std(stat_res[stat_res['set'] == 'va']['kappa']),\n",
    "                  np.std(stat_res[stat_res['set'] == 'va']['mcc']),np.std(stat_res[stat_res['set'] == 'va']['auc_prc'])],\n",
    "         \"Test\":[np.mean(stat_res[stat_res['set'] == 'te']['acc']),np.mean(stat_res[stat_res['set'] == 'te']['auc_roc']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['recall']),np.mean(stat_res[stat_res['set'] == 'te']['precision']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['f1']),np.mean(stat_res[stat_res['set'] == 'te']['kappa']),\n",
    "                np.mean(stat_res[stat_res['set'] == 'te']['mcc']),np.mean(stat_res[stat_res['set'] == 'te']['auc_prc'])],\n",
    "          \"Te_STD\":[np.std(stat_res[stat_res['set'] == 'te']['acc']),np.std(stat_res[stat_res['set'] == 'te']['auc_roc']),\n",
    "                   np.std(stat_res[stat_res['set'] == 'te']['recall']),np.std(stat_res[stat_res['set'] == 'te']['precision']),\n",
    "                   np.std(stat_res[stat_res['set'] == 'te']['f1']),np.std(stat_res[stat_res['set'] == 'te']['kappa']),\n",
    "                   np.std(stat_res[stat_res['set'] == 'te']['mcc']),np.std(stat_res[stat_res['set'] == 'te']['auc_prc']),]}\n",
    "dict1 = collections.OrderedDict(dict1)\n",
    "df = pd.DataFrame(dict1,index = None)\n",
    "df.to_csv('output/output_gbc.csv',index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2795f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.043542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.935537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_split</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <td>1.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_features</th>\n",
       "      <td>0.679405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Values\n",
       "n_estimators           257.000000\n",
       "learning_rate            0.043542\n",
       "subsample                0.935537\n",
       "min_samples_split        8.000000\n",
       "min_samples_leaf         1.000000\n",
       "max_depth                5.000000\n",
       "min_impurity_decrease    1.000842\n",
       "max_features             0.679405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option ( 'display.width', None)\n",
    "pd.set_option ( 'display.max_columns', None) #显示全部列\n",
    "hyper_parameters = best_hyper.iloc[0:1,8:-14].T\n",
    "hyper_parameters.rename(columns={0:'Values'},inplace=True) \n",
    "hyper_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c50b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-dgl]",
   "language": "python",
   "name": "conda-env-anaconda3-dgl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
